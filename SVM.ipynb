{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./boat-types-recognition/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating original data size ...\n",
      "Progress calculating: 100.00%\r"
     ]
    }
   ],
   "source": [
    "## Original Data Size\n",
    "print(\"Calculating original data size ...\")\n",
    "\n",
    "count = 0\n",
    "heights=[]\n",
    "widths=[]\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        if name.find(\".DS_Store\") == -1:\n",
    "            img_path = os.path.join(path, name)\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            w,h = img.size\n",
    "            widths.append(w)\n",
    "            heights.append(h)\n",
    "            count += 1\n",
    "            sys.stdout.write(\"Progress calculating: {:.2%}\\r\".format(count/(1462)))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "min_height = min(heights)\n",
    "min_width = min(widths)\n",
    "total = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image:  1462\n",
      "Min image height:  261\n",
      "Min image width:  309\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of image: \", total)\n",
    "print(\"Min image height: \", min_height)\n",
    "print(\"Min image width: \", min_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_W,resize_H = 100, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress calculating: 100.00%\r"
     ]
    }
   ],
   "source": [
    "#Generating same size, gray picture\n",
    "\n",
    "count = 0\n",
    "images = []\n",
    "labels = []\n",
    "index = 0\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        if name.find(\".DS_Store\") == -1:\n",
    "            img_path = os.path.join(path, name)\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            label = index\n",
    "            img_new = img.resize((resize_W,resize_H))\n",
    "            img_array = np.array(img_new).reshape(-1)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "            count += 1\n",
    "            sys.stdout.write(\"Progress calculating: {:.2%}\\r\".format(count/(1462)))\n",
    "            sys.stdout.flush()\n",
    "    index += 1\n",
    "            \n",
    "X = np.array(images)\n",
    "Y = np.array(labels)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1462, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting Test / Train sets ...\n"
     ]
    }
   ],
   "source": [
    "## Split Test / Train\n",
    "print(\"Spliting Test / Train sets ...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (1023, 10000)\n",
      "Y train size:  1023\n",
      "X test shape:  (439, 10000)\n",
      "Y test size:  439\n"
     ]
    }
   ],
   "source": [
    "## Data Size (after spliting)\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"Y train size: \", y_train.size)\n",
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"Y test size: \", y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF ...\n",
      "violation: 1.0\n",
      "violation: 0.1341189081075392\n",
      "violation: 0.08871852123358978\n",
      "Converged at iteration 3\n"
     ]
    }
   ],
   "source": [
    "## NMF\n",
    "print(\"NMF ...\")\n",
    "components = 1500\n",
    "nmf = NMF(n_components=components, init='random', random_state=0, tol=0.1, verbose=True)\n",
    "\n",
    "W = nmf.fit_transform(X_train)\n",
    "H = nmf.components_\n",
    "X_train_reduced = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train reduced shape: (1023, 1500)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train reduced shape:\",X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sandy\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best \"score\" for training data: 0.34017595307917886\n",
      "Best \"c\": 1\n",
      "Best \"kernel\": linear\n",
      "Best \"gamma\": auto_deprecated\n"
     ]
    }
   ],
   "source": [
    "# Set the parameter candidates\n",
    "parameter_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]\n",
    "\n",
    "# Create a classifier with the parameter candidates\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "\n",
    "# Train the classifier on training data\n",
    "clf.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Print out the results \n",
    "print('Best \"score\" for training data:', clf.best_score_)\n",
    "print('Best \"c\":',clf.best_estimator_.C)\n",
    "print('Best \"kernel\":',clf.best_estimator_.kernel)\n",
    "print('Best \"gamma\":',clf.best_estimator_.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SVC model \n",
    "print(\"Training......\")\n",
    "svc_model = svm.SVC(gamma=0.001,C=1., kernel='rbf')\n",
    "\n",
    "# Fit the data to the SVC model\n",
    "svc_model.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violation: 1.0\n",
      "violation: 0.6374588555027088\n",
      "violation: 0.43190837045946995\n",
      "violation: 0.3407747177170469\n",
      "violation: 0.29555411521196157\n",
      "violation: 0.2706012719071585\n",
      "violation: 0.24983628643802416\n",
      "violation: 0.2340132671995518\n",
      "violation: 0.22212428763270806\n",
      "violation: 0.21057149482547494\n",
      "violation: 0.20483732728045925\n",
      "violation: 0.1974717514789586\n",
      "violation: 0.19140476379524676\n",
      "violation: 0.18616905816639465\n",
      "violation: 0.17981271213413177\n",
      "violation: 0.17528718401191468\n",
      "violation: 0.16971510501575082\n",
      "violation: 0.16439409425990867\n",
      "violation: 0.16044604881954663\n",
      "violation: 0.15707910055734584\n",
      "violation: 0.15224498591415364\n",
      "violation: 0.14799075808236578\n",
      "violation: 0.1428400498984003\n",
      "violation: 0.1386914865898034\n",
      "violation: 0.13460241284405688\n",
      "violation: 0.1313990214208069\n",
      "violation: 0.12790180653357663\n",
      "violation: 0.12570381257938684\n",
      "violation: 0.12169585515017423\n",
      "violation: 0.11875355238478563\n",
      "violation: 0.11548756484147656\n",
      "violation: 0.11257563106406573\n",
      "violation: 0.11014323723972869\n",
      "violation: 0.10778970013832637\n",
      "violation: 0.10447839069580328\n",
      "violation: 0.10158855409257259\n",
      "violation: 0.0991110213829588\n",
      "Converged at iteration 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32574031890660593"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier to the test data, and view the accuracy score\n",
    "X_test_reduced = nmf.transform(X_test)\n",
    "svc_model.score(X_test_reduced, y_test)  \n",
    "\n",
    "# Train and score a new classifier with the grid search parameters\n",
    "\n",
    "svc_model.fit(X_train_reduced, y_train).score(X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing.....\n"
     ]
    }
   ],
   "source": [
    "# Predict the label of \"x test\"\n",
    "print(\"Testing.....\")\n",
    "\n",
    "y_hat = svc_model.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.32574031890660593\n",
      "precision: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.32574032]\n",
      "recall: [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "F1: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.49140893]\n"
     ]
    }
   ],
   "source": [
    "## Evaluations \n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, f1_score, roc_curve\n",
    "print(\"accuracy: \" + str(accuracy_score(y_test, y_hat)))\n",
    "print(\"precision: \" + str(precision_score(y_test, y_hat, average=None)))\n",
    "print(\"recall: \" + str(recall_score(y_test, y_hat, average=None)))\n",
    "print(\"F1: \" + str(f1_score(y_test, y_hat, average=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SVC model \n",
    "print(\"Training......\")\n",
    "svc_model = svm.SVC(gamma=0.001,C=100., kernel='linear')\n",
    "\n",
    "# Fit the data to the SVC model\n",
    "svc_model.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23234624145785876"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier to the test data, and view the accuracy score\n",
    "svc_model.score(X_test_reduced, y_test)  \n",
    "\n",
    "# Train and score a new classifier with the grid search parameters\n",
    "\n",
    "svc_model.fit(X_train_reduced, y_train).score(X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SVC model \n",
    "print(\"Training......\")\n",
    "svc_model = svm.SVC(gamma=0.001,C=100., kernel='poly')\n",
    "\n",
    "# Fit the data to the SVC model\n",
    "svc_model.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1252847380410023"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the classifier to the test data, and view the accuracy score\n",
    "svc_model.score(X_test_reduced, y_test)  \n",
    "\n",
    "# Train and score a new classifier with the grid search parameters\n",
    "\n",
    "svc_model.fit(X_train_reduced, y_train).score(X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
